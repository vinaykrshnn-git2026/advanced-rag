{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUosFop80pZl"
      },
      "source": [
        "#  Indexing and searching image based documents (using ColPali with Qdrant)\n",
        "\n",
        "We can retrieve documents with images such as user guides or old scanned documents. We will use an embedding model for the documents and the queries that supports images. We will also tune the vector database to efficiently store and search these embedding vectors.\n",
        "\n",
        "Here are the steps:\n",
        "* [Creating image collection index](#creating-image-collection-index)\n",
        "* [Searching the image index](#searching-the-image-index)\n",
        "* [Generating a reply based on the retrieved image](#generate-response-with-the-retrieved-images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMA8_V250pZn"
      },
      "source": [
        "## Visual Improvements"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd advanced-rag"
      ],
      "metadata": {
        "id": "HugCEYLWzjhI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9adce4bc-61a3-4ae0-cef4-c198ece52f89"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/advanced-rag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before installing other requirements, ensure compatible torch and torchvision versions.\n",
        "# The error indicates torchvision 0.24.0 requires torch 2.9.0, while current torch is 2.4.1.\n",
        "# We will uninstall existing torch, torchvision, and torchaudio and then install the required compatible versions.\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch==2.9.0 torchvision==0.24.0+cu121 torchaudio==2.9.0+cu121 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "!git clone https://github.com/guyernest/advanced-rag.git\n",
        "%cd advanced-rag\n",
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "id": "nQmsj3er6uYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe56d633-ce3a-43e6-83bf-3a5127204c43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.9.0+cpu\n",
            "Uninstalling torch-2.9.0+cpu:\n",
            "  Successfully uninstalled torch-2.9.0+cpu\n",
            "Found existing installation: torchvision 0.24.0+cpu\n",
            "Uninstalling torchvision-0.24.0+cpu:\n",
            "  Successfully uninstalled torchvision-0.24.0+cpu\n",
            "Found existing installation: torchaudio 2.9.0+cpu\n",
            "Uninstalling torchaudio-2.9.0+cpu:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cpu\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==2.9.0\n",
            "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.24.0+cu121 (from versions: 0.1.6, 0.2.0, 0.17.0, 0.17.0+cpu, 0.17.0+cu118, 0.17.0+cu121, 0.17.0+rocm5.6, 0.17.0+rocm5.7, 0.17.1, 0.17.1+cpu, 0.17.1+cu118, 0.17.1+cu121, 0.17.1+rocm5.6, 0.17.1+rocm5.7, 0.17.2, 0.17.2+cpu, 0.17.2+cu118, 0.17.2+cu121, 0.17.2+rocm5.6, 0.17.2+rocm5.7, 0.18.0, 0.18.0+cpu, 0.18.0+cu118, 0.18.0+cu121, 0.18.0+rocm5.7, 0.18.0+rocm6.0, 0.18.1, 0.18.1+cpu, 0.18.1+cu118, 0.18.1+cu121, 0.18.1+rocm5.7, 0.18.1+rocm6.0, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0, 0.22.0, 0.22.1, 0.23.0, 0.24.0, 0.24.1, 0.25.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.24.0+cu121\u001b[0m\u001b[31m\n",
            "\u001b[0mCloning into 'advanced-rag'...\n",
            "remote: Enumerating objects: 281, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 281 (delta 3), reused 3 (delta 3), pack-reused 276 (from 2)\u001b[K\n",
            "Receiving objects: 100% (281/281), 18.84 MiB | 26.17 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n",
            "/content/advanced-rag\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.7/163.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'aiohappyeyeballs' candidate (version 2.4.2 at https://files.pythonhosted.org/packages/13/64/40165ff77ade5203284e3015cf88e11acb07d451f6bf83fff71192912a0d/aiohappyeyeballs-2.4.2-py3-none-any.whl (from https://pypi.org/simple/aiohappyeyeballs/) (requires-python:>=3.8))\n",
            "Reason for being yanked: Regression: https://github.com/aio-libs/aiohappyeyeballs/issues/100\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m658.1/658.1 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.4/198.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.7/51.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.9/52.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.5/320.5 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.0/319.0 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.3/185.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.3/683.3 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.9/258.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.1/789.1 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.6/241.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.0/358.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.8/434.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.1/66.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.0/797.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.1/25.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.1/30.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.1/490.1 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "timm 1.0.24 requires torchvision, which is not installed.\n",
            "fastai 2.8.6 requires torchvision>=0.11, which is not installed.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.3 which is incompatible.\n",
            "opencv-python-headless 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires tqdm>=4.67, but you have tqdm 4.66.5 which is incompatible.\n",
            "grain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 4.25.5 which is incompatible.\n",
            "db-dtypes 1.5.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "google-genai 1.60.0 requires anyio<5.0.0,>=4.8.0, but you have anyio 4.6.0 which is incompatible.\n",
            "google-genai 1.60.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "google-genai 1.60.0 requires pydantic<3.0.0,>=2.9.0, but you have pydantic 2.8.2 which is incompatible.\n",
            "albumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 2.8.2 which is incompatible.\n",
            "sse-starlette 3.2.0 requires anyio>=4.7.0, but you have anyio 4.6.0 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "umap-learn 0.5.11 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\n",
            "holoviews 1.22.1 requires narwhals>=2, but you have narwhals 1.9.3 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "bokeh 3.7.3 requires narwhals>=1.13, but you have narwhals 1.9.3 which is incompatible.\n",
            "google-cloud-bigquery 3.40.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\n",
            "ydf 0.14.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.5 which is incompatible.\n",
            "opencv-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "mcp 1.26.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.8.2 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.3.1 which is incompatible.\n",
            "dataproc-spark-connect 1.0.1 requires tqdm>=4.67, but you have tqdm 4.66.5 which is incompatible.\n",
            "diffusers 0.36.0 requires huggingface-hub<2.0,>=0.34.0, but you have huggingface-hub 0.25.1 which is incompatible.\n",
            "typeguard 4.4.4 requires typing_extensions>=4.14.0, but you have typing-extensions 4.12.2 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.5 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "xarray 2025.12.0 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "gradio 5.50.0 requires huggingface-hub<2.0,>=0.33.5, but you have huggingface-hub 0.25.1 which is incompatible.\n",
            "google-adk 1.23.0 requires anyio<5.0.0,>=4.9.0, but you have anyio 4.6.0 which is incompatible.\n",
            "google-adk 1.23.0 requires requests<3.0.0,>=2.32.4, but you have requests 2.32.3 which is incompatible.\n",
            "google-adk 1.23.0 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\n",
            "wheel 0.46.3 requires packaging>=24.0, but you have packaging 23.2 which is incompatible.\n",
            "panel 1.8.6 requires narwhals>=2, but you have narwhals 1.9.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.66.1 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3ZqU3mvXV_oP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH3GFiUrS8pC",
        "outputId": "b10980ae-8c3c-4905-e158-911f6f721509"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy all pdf files from Drive to RAG Labs\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import fnmatch\n",
        "\n",
        "# Define source and destination root paths within your mounted Drive\n",
        "# Replace 'SourceFolder' and 'DestinationFolder' with your actual folder names/paths\n",
        "SRC_ROOT = '/content/drive/MyDrive'\n",
        "DEST_ROOT = '/content/drive/MyDrive/RAG_Labs/pdf_files'\n",
        "\n",
        "# 2. Create destination folder if it doesn't exist\n",
        "if not os.path.exists(DEST_ROOT):\n",
        "    os.makedirs(DEST_ROOT)\n",
        "    print(f\"Created folder: {DEST_ROOT}\")\n",
        "\n",
        "# 3. Recursive copy with flattening and skipping\n",
        "files_copied = 0\n",
        "files_skipped = 0\n",
        "\n",
        "for root, dirs, files in os.walk(SRC_ROOT):\n",
        "    for file in files:\n",
        "        if file.lower().endswith('.pdf'):\n",
        "            source_file_path = os.path.join(root, file)\n",
        "            destination_file_path = os.path.join(DEST_ROOT, file)\n",
        "\n",
        "            # Check if file exists to skip\n",
        "            if not os.path.exists(destination_file_path):\n",
        "                shutil.copy2(source_file_path, destination_file_path)\n",
        "                print(f\"Copied: {file}\")\n",
        "                files_copied += 1\n",
        "            else:\n",
        "                print(f\"Skipped (exists): {file}\")\n",
        "                files_skipped += 1\n",
        "\n",
        "print(f\"\\nSummary:\\nCopied: {files_copied}\\nSkipped: {files_skipped}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BkF7PzlKV9iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating directory for data files"
      ],
      "metadata": {
        "id": "IbFpw1nDK7i9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# #target_dir = \"/content/advanced-rag/data/drivers-license\"\n",
        "# target_dir = \"/content/advanced-rag/data/passport\"\n",
        "# os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for file_name in uploaded.keys():\n",
        "#   new_path = os.path.join(target_dir, file_name)\n",
        "#   os.rename(file_name, new_path)\n",
        "#   print(f\"Moved '{file_name}' to '{new_path}'\")\n"
      ],
      "metadata": {
        "id": "N9yWbWLWyD27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Move files between directories"
      ],
      "metadata": {
        "id": "_vhquzsDb0Ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "# import os\n",
        "\n",
        "# source_dir = '/content/advanced-rag/data/license'\n",
        "# destination_dir = '/content/advanced-rag/data/passport'\n",
        "\n",
        "# # Ensure the destination directory exists\n",
        "# if not os.path.exists(destination_dir):\n",
        "#     os.makedirs(destination_dir) # Creates parent directories if needed\n",
        "\n",
        "# # Get list of files in the source directory\n",
        "# files_to_move = os.listdir(source_dir)\n",
        "\n",
        "# for file_name in files_to_move:\n",
        "#     # Construct full paths for source and destination\n",
        "#     source_path = os.path.join(source_dir, file_name)\n",
        "#     destination_path = os.path.join(destination_dir, file_name)\n",
        "\n",
        "#     try:\n",
        "#         shutil.move(source_path, destination_path)\n",
        "#         print(f\"Moved '{file_name}' to '{destination_dir}'\")\n",
        "#     except shutil.Error as e:\n",
        "#         print(f\"Error moving file '{file_name}': {e}\")\n"
      ],
      "metadata": {
        "id": "aDhhcmUacB5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enhanced Visualisation"
      ],
      "metadata": {
        "id": "l_2OpkptMYBs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-a8UUn6n0pZo"
      },
      "outputs": [],
      "source": [
        "from rich.console import Console\n",
        "from rich_theme_manager import Theme, ThemeManager\n",
        "import pathlib\n",
        "\n",
        "theme_dir = pathlib.Path(\"themes\")\n",
        "theme_manager = ThemeManager(theme_dir=theme_dir)\n",
        "dark = theme_manager.get(\"dark\")\n",
        "\n",
        "# Create a console with the dark theme\n",
        "console = Console(theme=dark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cA9iS_Uh0pZo"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzqcHISl0pZo"
      },
      "source": [
        "## Creating image collection index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wmBWri10pZo"
      },
      "source": [
        "### Converting PDF files into images\n",
        "\n",
        "We don't want to rely on text extraction from the PDF files, and we want to focus on the visual aspects of the pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jGPWTOfD0pZo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pdf2image.pdf2image import convert_from_path, PDFPageCountError\n",
        "\n",
        "def convert_pdfs_to_images(pdf_folder):\n",
        "    pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith(\".pdf\")]\n",
        "    all_images = {}\n",
        "    skipped_pdfs = []\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        pdf_path = os.path.join(pdf_folder, pdf_file)\n",
        "        try:\n",
        "            images = convert_from_path(pdf_path)\n",
        "            all_images[pdf_file] = images\n",
        "        except PDFPageCountError as e:\n",
        "            print(f\"Skipping '{pdf_file}' due to PDFPageCountError: {e}\")\n",
        "            skipped_pdfs.append(pdf_file)\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping '{pdf_file}' due to an unexpected error: {e}\")\n",
        "            skipped_pdfs.append(pdf_file)\n",
        "\n",
        "    if skipped_pdfs:\n",
        "        print(\"\\nSummary of skipped PDF files:\")\n",
        "        for s_pdf in skipped_pdfs:\n",
        "            print(f\"- {s_pdf}\")\n",
        "    else:\n",
        "        print(\"No PDF files were skipped.\")\n",
        "\n",
        "    return all_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TwoPeuVM0pZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9cd985-81bd-4244-9d59-56a2cd62baee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
            "No PDF files were skipped.\n"
          ]
        }
      ],
      "source": [
        "# all_images = convert_pdfs_to_images(\"data/ikea/\")\n",
        "# Install poppler-utils\n",
        "!apt-get install poppler-utils\n",
        "\n",
        "all_images = convert_pdfs_to_images(\"/content/advanced-rag/data/pdf_files\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "09d8fd8c",
        "outputId": "15f8841f-08ef-4e4f-c735-6d15ae0324ec"
      },
      "source": [
        "import os\n",
        "from pdf2image.pdf2image import convert_from_path, PDFPageCountError\n",
        "!apt-get install poppler-utils\n",
        "\n",
        "pdf_folder = \"/content/advanced-rag/data/pdf_files\"\n",
        "pdf_files = [f for f in os.listdir(pdf_folder) if f.lower().endswith(\".pdf\")]\n",
        "\n",
        "print(f\"Checking {len(pdf_files)} PDF files for errors...\")\n",
        "\n",
        "problematic_pdfs = []\n",
        "for pdf_file in pdf_files:\n",
        "    pdf_path = os.path.join(pdf_folder, pdf_file)\n",
        "    try:\n",
        "        # Attempt to get page count, which triggers the error for protected PDFs\n",
        "        convert_from_path(pdf_path, first_page=1, last_page=1) # only try first page to speed up\n",
        "    except PDFPageCountError as e:\n",
        "        # print(f\"ERROR: '{pdf_file}' caused a PDFPageCountError: {e}\") # Removed print statement\n",
        "        problematic_pdfs.append(pdf_file)\n",
        "    except Exception as e:\n",
        "        # print(f\"ERROR: An unexpected error occurred with '{pdf_file}': {e}\") # Removed print statement\n",
        "        problematic_pdfs.append(pdf_file) # Added to problematic list even for general exceptions\n",
        "\n",
        "if not problematic_pdfs:\n",
        "    print(\"No problematic PDF files found.\")\n",
        "else:\n",
        "    print(f\"Found {len(problematic_pdfs)} problematic PDF files.\")\n",
        "    # The list 'problematic_pdfs' now holds the names of the files without printing them here\n",
        "    # print(\"\\nSummary of problematic PDF files:\") # Removed print statement\n",
        "    # for p_pdf in problematic_pdfs: # Removed print statement\n",
        "    #     print(f\"- {p_pdf}\") # Removed print statement"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 2 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.12 [186 kB]\n",
            "Fetched 186 kB in 0s (748 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 117540 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.12_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.12) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/advanced-rag/data/pdf_files'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1576149226.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpdf_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/advanced-rag/data/pdf_files\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpdf_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Checking {len(pdf_files)} PDF files for errors...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/advanced-rag/data/pdf_files'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l3D7InX30pZp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "7041a324-ceb6-4c56-8eb7-bd0d594907f1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'console' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1273703404.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconsole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'console' is not defined"
          ]
        }
      ],
      "source": [
        "console.print(all_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yWOdoL-0pZq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1,2 , figsize=(15, 10))\n",
        "\n",
        "first_pdf_key = next(iter(all_images))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img = all_images[first_pdf_key][i]\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5n_OMYu0pZr"
      },
      "outputs": [],
      "source": [
        "from colpali_engine.models import ColPali, ColPaliProcessor\n",
        "import torch\n",
        "\n",
        "\n",
        "# Initialize ColPali model and processor\n",
        "model_name = (\n",
        "    \"vidore/colpali-v1.2\"  # Use the latest version available\n",
        ")\n",
        "colpali_model = ColPali.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"cuda:0\",  # Use \"cuda:0\" for GPU, \"cpu\" for CPU, or \"mps\" for Apple Silicon\n",
        ")\n",
        "colpali_processor = ColPaliProcessor.from_pretrained(\n",
        "    \"vidore/colpaligemma-3b-pt-448-base\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03fyTS6L0pZs"
      },
      "outputs": [],
      "source": [
        "console.print(colpali_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK6t9qgR0pZs"
      },
      "outputs": [],
      "source": [
        "sample_image = all_images[first_pdf_key][0]\n",
        "with torch.no_grad():\n",
        "    sample_batch = colpali_processor.process_images([sample_image]).to(\n",
        "        colpali_model.device\n",
        "    )\n",
        "    sample_embedding = colpali_model(**sample_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbw7pyUt0pZt"
      },
      "outputs": [],
      "source": [
        "console.print(sample_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O67Rn30t0pZt"
      },
      "outputs": [],
      "source": [
        "from rich.table import Table\n",
        "\n",
        "table = Table(title=\"Document Embedding\")\n",
        "table.add_column(\"Documents\", style=\"cyan\", no_wrap=True)\n",
        "table.add_column(\"Tokens\", style=\"bright_yellow\")\n",
        "table.add_column(\"Vector Size\", style=\"green\")\n",
        "\n",
        "table.add_row(\n",
        "    str(sample_embedding.shape[0]),\n",
        "    str(sample_embedding.shape[1]),\n",
        "    str(sample_embedding.shape[2])\n",
        ")\n",
        "\n",
        "console.print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store embeddings in a persistent Store"
      ],
      "metadata": {
        "id": "tGwUGLbupQZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install ChromaDB\n",
        "import os\n",
        "!pip install chromadb\n",
        "\n",
        "# Setup Persistent Storage\n",
        "\n",
        "persistent_store = '/content/advanced-rag/data/persistent_store'\n",
        "\n",
        "# Ensure the destination directory exists\n",
        "if not os.path.exists(persistent_store):\n",
        "    os.makedirs(persistent_store) # Creates parent directories if needed\n",
        "%cd persistent_store\n",
        "\n",
        "#client = chromadb.PersistentClient(path=\"./chroma_db\")"
      ],
      "metadata": {
        "id": "WjdJ3nKIpMf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUTbEjc90pZu"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient\n",
        "\n",
        "qdrant_client = QdrantClient(\n",
        "   # \":memory:\"\n",
        "    path=\"/content/advanced-rag/data/persistent_store\"\n",
        ")  # Use \":memory:\" for in-memory database or \"path/to/db\" for persistent storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW60ka5D0pZu"
      },
      "outputs": [],
      "source": [
        "vector_size = sample_embedding.shape[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmxxfQ_X0pZu"
      },
      "outputs": [],
      "source": [
        "from qdrant_client.http import models\n",
        "\n",
        "multi_vector_params = models.VectorParams(\n",
        "    size=vector_size,\n",
        "    distance=models.Distance.COSINE,\n",
        "    multivector_config=models.MultiVectorConfig(\n",
        "        comparator=models.MultiVectorComparator.MAX_SIM\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DvpEK4o0pZu"
      },
      "source": [
        "### Reducing vector memory using Quantization\n",
        "\n",
        "We can define a `ScalarQuantizationConfig` and pass it when creating the collection. On the server side, Qdrant will convert the vectors to 8-bit integers, reducing the memory footprint and speeding up the search process. You can also switch on or off the `always_ram` parameter, keeping the vectors in RAM. This will increase performance at the cost of memory usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t1Ji6up0pZu"
      },
      "outputs": [],
      "source": [
        "scalar_quant = models.ScalarQuantizationConfig(\n",
        "    type=models.ScalarType.INT8,\n",
        "    quantile=0.99,\n",
        "    always_ram=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-69kGnr0pZu"
      },
      "outputs": [],
      "source": [
        "collection_name=\"driver-license\"\n",
        "\n",
        "qdrant_client.recreate_collection(\n",
        "    collection_name=collection_name,  # the name of the collection\n",
        "    on_disk_payload=True,  # store the payload on disk\n",
        "    optimizers_config=models.OptimizersConfigDiff(\n",
        "        indexing_threshold=100\n",
        "    ),  # it can be useful to swith this off when doing a bulk upload and then manually trigger the indexing once the upload is done\n",
        "    vectors_config=models.VectorParams(\n",
        "        size=vector_size,\n",
        "        distance=models.Distance.COSINE,\n",
        "        multivector_config=models.MultiVectorConfig(\n",
        "            comparator=models.MultiVectorComparator.MAX_SIM\n",
        "        ),\n",
        "        quantization_config=models.ScalarQuantization(\n",
        "            scalar=scalar_quant,\n",
        "        ),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRDFqv4K0pZv"
      },
      "source": [
        "### Upserting the encoded images into the vector database\n",
        "\n",
        "We define a helper function to upload points to Qdrant via the client. We use the stamina library to enable retries in case of network issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7PvpnjB0pZv"
      },
      "outputs": [],
      "source": [
        "import stamina\n",
        "\n",
        "@stamina.retry(on=Exception, attempts=3)\n",
        "def upsert_to_qdrant(batch):\n",
        "    try:\n",
        "        qdrant_client.upsert(\n",
        "            collection_name=collection_name,\n",
        "            points=points,\n",
        "            wait=False,\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error during upsert: {e}\")\n",
        "        return False\n",
        "    return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nplRrLS0pZw"
      },
      "source": [
        "We will now upload the vectors to qdrant. We do this by creating batches of data, passing it through the ColPali model and then adding the embeddings to a Qdrant `PointStruct`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5BnJtRh0pZw"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "from tqdm import tqdm\n",
        "\n",
        "batch_size = 2  # Adjust based on your GPU memory constraints\n",
        "\n",
        "total_images = sum(len(images) for images in all_images.values())\n",
        "\n",
        "# Use tqdm to create a progress bar\n",
        "with tqdm(total=total_images, desc=\"Indexing Progress\") as pbar:\n",
        "    for doc_id, pdf_file in enumerate(all_images.keys()):\n",
        "        for i in range(0, len(all_images[pdf_file]), batch_size):\n",
        "            images = all_images[pdf_file][i : i + batch_size]\n",
        "\n",
        "            # Process and encode images\n",
        "            with torch.no_grad():\n",
        "                batch_images = colpali_processor.process_images(images).to(\n",
        "                    colpali_model.device\n",
        "                )\n",
        "                image_embeddings = colpali_model(**batch_images)\n",
        "\n",
        "            # Prepare points for Qdrant\n",
        "            points = []\n",
        "            for j, embedding in enumerate(image_embeddings):\n",
        "                unique_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, f\"{doc_id}.{i + j}\"))\n",
        "                # Convert the embedding to a list of vectors\n",
        "                multivector = embedding.cpu().float().numpy().tolist()\n",
        "                points.append(\n",
        "                    models.PointStruct(\n",
        "                        id=unique_id,\n",
        "                        vector=multivector,  # This is now a list of vectors\n",
        "                        payload={\n",
        "                            \"doc\": pdf_file,\n",
        "                            \"page\": i+j+1\n",
        "                        },  # can also add other metadata/data\n",
        "                    )\n",
        "                )\n",
        "            # Upload points to Qdrant\n",
        "            try:\n",
        "                upsert_to_qdrant(points)\n",
        "            # clown level error handling here 🤡\n",
        "            except Exception as e:\n",
        "                print(f\"Error during upsert: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Update the progress bar\n",
        "            pbar.update(batch_size)\n",
        "\n",
        "print(\"Indexing complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw3XKF1N0pZw"
      },
      "source": [
        "If you had the indexing off during the upload you can trigger an index by setting a lower indexing threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P3LZnaE0pZw"
      },
      "outputs": [],
      "source": [
        "qdrant_client.update_collection(\n",
        "    collection_name=collection_name,\n",
        "    optimizer_config=models.OptimizersConfigDiff(indexing_threshold=10),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lp_q-OIV0pZw"
      },
      "outputs": [],
      "source": [
        "console.print(\n",
        "    qdrant_client\n",
        "    .get_collection(collection_name)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSFV5DLw0pZx"
      },
      "outputs": [],
      "source": [
        "console.print(\n",
        "    qdrant_client\n",
        "    .scroll(\n",
        "        collection_name=collection_name,\n",
        "        limit=20\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3Dh_6C80pZx"
      },
      "source": [
        "## Searching the image index\n",
        "\n",
        "Once we uploaded the encoded images to the vector database, we can query it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LovMCahF0pZx"
      },
      "outputs": [],
      "source": [
        "# query_text = \"What is the license number?\"\n",
        "query_text = \"What is Savitha's license number?\"\n",
        "with torch.no_grad():\n",
        "    batch_query = colpali_processor.process_queries([query_text]).to(\n",
        "        colpali_model.device\n",
        "    )\n",
        "    query_embedding = colpali_model(**batch_query)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgudayCs0pZx"
      },
      "outputs": [],
      "source": [
        "console.print(query_embedding.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYVYbY8s0pZx"
      },
      "outputs": [],
      "source": [
        "# Convert the query embedding to a list of vectors\n",
        "multivector_query = query_embedding[0].cpu().float().numpy().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi8yBIz-0pZx"
      },
      "outputs": [],
      "source": [
        "search_result = qdrant_client.query_points(\n",
        "    collection_name=collection_name,\n",
        "    query=multivector_query,\n",
        "    limit=3,\n",
        "    timeout=60,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD0VtYjp0pZx"
      },
      "outputs": [],
      "source": [
        "console.print(search_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvrCe2Xs0pZx"
      },
      "source": [
        "### Show the search results images\n",
        "\n",
        "We can display the images that were retrieved by the vector search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTYJfFFT0pZx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the top 3 images from the search result for display\n",
        "top_images = search_result.points[:6]\n",
        "\n",
        "# Create a figure with subplots for each image\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 10))\n",
        "\n",
        "# Iterate over the top images and plot each one\n",
        "for i, point in enumerate(top_images):\n",
        "    pdf_file = point.payload.get('doc')\n",
        "    page_num = int(point.payload.get('page')) - 1\n",
        "    img = all_images[pdf_file][page_num]\n",
        "    axs[i].imshow(img)\n",
        "    axs[i].set_title(f\"Score: {point.score}, \\n Doc: {pdf_file}\")\n",
        "    axs[i].axis('off')  # Do not display axes for better visualization\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vam87iHc0pZx"
      },
      "source": [
        "## Generate response with the retrieved image(s)\n",
        "\n",
        "In the **A**ugmentation step we encode the retrieved image using base64 and send it as part of the prompt to the generation model, alongside the user's query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW0HDa1r0pZx"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "top_image = search_result.points[0]\n",
        "pdf_file = top_image.payload.get('doc')\n",
        "page_num = int(top_image.payload.get('page')) - 1\n",
        "image = all_images[pdf_file][page_num]\n",
        "display(image)\n",
        "\n",
        "buffered = BytesIO()\n",
        "image.save(buffered, format=\"PNG\")  # You may choose another format if needed\n",
        "img_bytes = buffered.getvalue()\n",
        "\n",
        "image1_media_type = \"image/png\"\n",
        "\n",
        "image1_data = base64.standard_b64encode(img_bytes).decode(\"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk8KlWHa0pZ1"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# Get the secret value from Colab's secrets manager\n",
        "openai_key = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=openai_key)\n",
        "\n",
        "message = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # or gpt-4o-mini\n",
        "   messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\",\n",
        "                 \"text\": query_text\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": f\"data:image/jpeg;base64,{image1_data}\"\n",
        "                    },\n",
        "                },\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=2000,\n",
        ")\n",
        "\n",
        "console.print(message)"
      ],
      "metadata": {
        "id": "K1ZaN-GQI29k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxImRt6C0pZ1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}